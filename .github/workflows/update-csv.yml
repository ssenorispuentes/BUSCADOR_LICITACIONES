name: Ejecutar scraping y actualizar CSV

on:
  schedule:
    - cron: '0 6 * * 1'  # Lunes a las 06:00 UTC
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout del repositorio
      uses: actions/checkout@v3
      with:
        persist-credentials: false

    - name: Instalar Chrome
      run: |
        sudo apt update
        sudo apt install -y wget unzip xvfb libxi6 libgconf-2-4 libnss3 libasound2 libatk1.0-0 libatk-bridge2.0-0 libcups2 libxss1 libxcomposite1 libxrandr2 libxdamage1 libgbm1 libxshmfence1
        sudo apt install -y chromium-browser

    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Instalar dependencias
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
        python -m spacy download es_core_news_sm
        python -m nltk.downloader stopwords

    - name: Ejecutar script de scraping
      run: xvfb-run -a python main_scraping.py --usar_scraping

    - name: Subir CSV actualizado al repositorio
      run: |
        git config user.name "github-actions"
        git config user.email "github-actions@github.com"
        git add licitaciones.csv
        git commit -m "Actualizar CSV autom√°ticamente"
        git push https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }} HEAD:main
